# Pipeline de Estimativa de Pose 6D com G√™meo Digital

Este projeto implementa um pipeline completo, escrito em Python, para estimar em tempo real a pose 6D (posi√ß√£o e orienta√ß√£o) de objetos vistos por uma c√¢mera Intel RealSense D456. A arquitetura combina detec√ß√£o 2D com YOLOv8, reconstru√ß√£o 3D via nuvem de pontos e uma an√°lise geom√©trica *model-free* que dispensa arquivos CAD. O resultado final √© visualizado em um g√™meo digital interativo que reflete continuamente a cena real.

---

## üß† Vis√£o Geral da Solu√ß√£o

1. **Aquisi√ß√£o RGB-D**
   - `RealSenseCamera` inicializa o pipeline da D456, alinha automaticamente profundidade e cor e exp√µe os par√¢metros intr√≠nsecos da c√¢mera para o Open3D.
   - Cada frame retorna um par `(depth_image, color_image)` diretamente utiliz√°vel pelo pipeline.

2. **Reconstru√ß√£o 3D da Cena**
   - As imagens RGB-D s√£o convertidas em uma nuvem de pontos colorida (`PointCloud`) orientada no referencial da c√¢mera.
   - Um corte de profundidade evita ru√≠dos distantes e a nuvem √© ‚Äúdesvirada‚Äù para alinhar eixos com o mundo real.

3. **Detec√ß√£o 2D com YOLOv8**
   - `ObjectDetector` utiliza o modelo pr√©-treinado `yolov8n.pt` (baixado automaticamente pelo pacote `ultralytics`).
   - Cada detec√ß√£o fornece classe, *bounding box* e confian√ßa.

4. **Segmenta√ß√£o 3D por *Bounding Box***
   - Para cada detec√ß√£o, o volume 3D correspondente √© recortado da nuvem de pontos usando `SelectionPolygonVolume`.
   - Pequenos ru√≠dos s√£o reduzidos com *voxel downsampling*.

5. **An√°lise de Forma e Pose (Model-Free)**
   - `ShapeAnalyzer` obt√©m a `OrientedBoundingBox` do objeto, classifica a geometria em **caixa**, **cilindro**, **esfera** ou **bloco gen√©rico** e extrai:
     - Pose 6D (matriz 4√ó4 constru√≠da com o centro e a rota√ß√£o da OBB).
     - Dimens√µes (extents) do objeto.
   - A cor predominante √© estimada a partir da nuvem segmentada.

6. **G√™meo Digital N√£o-Bloqueante**
   - `DigitalTwinVisualizer` usa o `Visualizer` do Open3D em modo n√£o bloqueante.
   - A cena renderizada inclui a nuvem completa e as primitivas geom√©tricas sobrepostas com a pose inferida e cor m√©dia do objeto.
   - O loop principal atualiza o visualizador a cada novo frame, mantendo a aplica√ß√£o responsiva.

---

## üìÇ Estrutura do Reposit√≥rio

```
.
‚îú‚îÄ‚îÄ requirements.txt          # Depend√™ncias Python do projeto
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ main.py               # Pipeline completo de pose e g√™meo digital
    ‚îú‚îÄ‚îÄ ...                   # Outros scripts auxiliares de explora√ß√£o
```

O fluxo oficial est√° concentrado em `src/main.py`. Os demais arquivos no diret√≥rio `src/` podem ser explorados para testes adicionais, mas n√£o fazem parte do pipeline atual.

---

## üß± Componentes Principais (`src/main.py`)

- **RealSenseCamera**  
  Configura streaming sincronizado de profundidade e cor, realiza o alinhamento (depth ‚Üí color) e retorna frames prontos para o Open3D.

- **ObjectDetector**  
  Abstrai o uso do YOLOv8, encapsulando o limiar de confian√ßa e entregando uma lista de detec√ß√µes por frame.

- **ShapeAnalyzer**  
  Converte a nuvem segmentada em uma bounding box orientada:
  - Compara extens√µes relativas para decidir entre ‚Äúsphere‚Äù, ‚Äúcylinder‚Äù, ‚Äúbox‚Äù ou ‚Äúblock‚Äù.
  - Retorna pose 6D, dimens√µes e a pr√≥pria OBB.

- **PoseEstimationPipeline**  
  Orquestra as etapas de captura, reconstru√ß√£o, dete√ß√£o, segmenta√ß√£o e an√°lise. Produz, para cada objeto, um dicion√°rio com:
  - `class_name`, `confidence`, `shape`, `pose`, `dimensions`, `color`, `point_cloud`.

- **DigitalTwinVisualizer**  
  Mant√©m uma janela Open3D aberta, atualizando continuamente:
  - Nuvem de pontos completa para contexto.
  - Primitivas geom√©tricas dimensionadas e transformadas pela pose 6D estimada.
  - Colora√ß√£o uniforme baseada na cor m√©dia medida pela c√¢mera.

---

## üß© Pr√©-requisitos

1. **Hardware**
   - Intel RealSense D456 (ou compat√≠vel com SDK 2.0).

2. **Software**
   - Python 3.10 ou superior recomendado.
   - [Intel RealSense SDK 2.0](https://github.com/IntelRealSense/librealsense) instalado com suporte √† c√¢mera (Linux: `apt`, Windows: instalador oficial).
   - Compila√ß√£o do m√≥dulo `pyrealsense2` compat√≠vel com a vers√£o do SDK e do Python (j√° listado em `requirements.txt`).
   pip install -r requirements.txt

3. **Sistema Operacional**
   - Linux (Ubuntu 20.04+ testado).

---

## ‚öôÔ∏è Configurando o Ambiente

1. **Clonar o reposit√≥rio**
   ```bash
   git clone https://github.com/kevinadolf/ic-computer-vision.git
   cd <seu_repositorio>
   ```

2. **Criar ambiente virtual (opcional, recomendado); instru√ß√£o para Linux**
   ```
   python -m venv .venv
   source .venv/bin/activate
   ```

3. **Instalar depend√™ncias**
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```
   > O pacote `ultralytics` baixa automaticamente o peso `yolov8n.pt` na primeira execu√ß√£o.

4. **Testar se o m√≥dulo RealSense responde**
   ```bash
   python - <<'PY'
   import pyrealsense2 as rs
   ctx = rs.context()
   print(f"C√¢meras detectadas: {len(ctx.devices)}")
   PY
   ```

---

## ‚ñ∂Ô∏è Executando o Pipeline

1. Conecte a c√¢mera Intel RealSense D456.
2. Com o ambiente ativado, rode:
   ```bash
   python src/main.py
   ```
3. A janela ‚ÄúDigital Twin‚Äù abrir√° automaticamente. A cada frame:
   - O terminal reporta objetos detectados, forma estimada, dimens√µes e centro.
   - A visualiza√ß√£o mostra nuvem de pontos + primitivas alinhadas.

4. **Encerrar:** pressione `Ctrl+C` no terminal. O pipeline fecha a janela e libera a c√¢mera.

---

## üîß Ajustes Importantes

- **Modelo YOLO**: altere `model_path` em `ObjectDetector` para usar variantes maiores (`yolov8s.pt`, `yolov8m.pt`, etc.) se a GPU suportar.
- **Limiar de confian√ßa**: ajuste `confidence_threshold` caso ocorram muitas detec√ß√µes falsas.
- **Segmenta√ß√£o**: `min_points`, `voxel_size` e profundidade m√°xima (`max_depth`) controlam o filtro de ru√≠dos na nuvem de pontos.
- **Classifica√ß√£o geom√©trica**: refine `sphere_tol`, `base_tol` e `diff_tol` em `ShapeAnalyzer` de acordo com seus objetos reais.
- **Visualiza√ß√£o**: modifique a cor padr√£o ou adicione eixos locais extras na classe `DigitalTwinVisualizer`.

---

## üß™ Estrat√©gias de Teste

- **Valida√ß√£o offline**: salve pares RGB-D (`np.savez`) e alimente o m√©todo `run_single_frame` com imagens gravadas para depura√ß√£o sem hardware.
- **Inspe√ß√£o de limites**: teste objetos n√£o r√≠gidos ou com geometrias complexas para avaliar a classifica√ß√£o ‚Äúblock‚Äù.
- **Performance**: monitore uso de CPU/GPU quando aumentar a resolu√ß√£o ou trocar o modelo YOLO.

---

## üöÄ Pr√≥ximas Evolu√ß√µes Sugeridas

1. **Rastreamento temporal**: introduzir previs√£o/associa√ß√£o entre frames (ex.: filtro de Kalman) para suavizar poses.
2. **Fus√£o multi-frame**: acumular nuvens de pontos ao longo do tempo para melhorar a robustez em ambientes com oclus√µes.
3. **Classifica√ß√£o h√≠brida**: treinar um classificador leve (ex.: PointNet) sobre as OBBs para diferenciar objetos com formas semelhantes.
4. **Integra√ß√£o ROS 2**: publicar `PoseStamped` e `MarkerArray` para uso direto em manipuladores rob√≥ticos.
5. **Persist√™ncia**: registrar hist√≥ricos de poses e gerar estat√≠sticas de confian√ßa por classe.

---

## üìù Cr√©ditos e Licen√ßa

- Autor: Kevin Adolfo Carvalho Koberstain de Ara√∫jo / 202110036511
- Licen√ßa: [MIT](LICENSE)
